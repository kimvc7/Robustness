{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "juvenile-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"vision\"\n",
    "results_dir = './results/' + experiment_name + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "renewable-wisdom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4705 config files created\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"ticks\")\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import os \n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "    \n",
    "import runs.config_experiments_vision as run\n",
    "experiment_list = run.config_experiments(results_dir, create_json=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "certified-victim",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_attacks = [\"bound\", \"l1_pgd_norm\", \"l1_fgm_norm\", \"linf_pgd\", \"l2_pgd_norm\", \"linf_fgsm\", \"l2_fgm_norm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "minimal-singapore",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "list_entries = []\n",
    "for net in ['ThreeLayer']:\n",
    "    for dataset_id,dataset_name in zip([0,66,67],['MNIST','Fashion', 'CIFAR']):\n",
    "\n",
    "        #Find an experiment of the dataset_id to get the epsilons\n",
    "        for idx,_ in enumerate(experiment_list[1:]):\n",
    "            if experiment_list[idx+1]['data_set'] == dataset_id: \n",
    "                break\n",
    "        \n",
    "        for attack in name_attacks:\n",
    "\n",
    "            file_name = results_dir + experiment_list[idx+1]['model_name'] + '/results/acc_' + 'val' + '_' + attack + '.pkl'\n",
    "            if not os.path.isfile(file_name):\n",
    "                print(\"Missing!! \" + file_name)\n",
    "                continue\n",
    "            with open(file_name, 'rb') as f:\n",
    "                tmp = pickle.load(f)\n",
    "                \n",
    "\n",
    "\n",
    "            for idx_epsilon, cv_epsilon in enumerate(list(tmp.keys())):\n",
    "                # Hash table of parameters\n",
    "                parameters = {\"epsilon\": {}, \"standarize\": {}, \"backbone\": {}, \"initial_learning_rate\": {}, \n",
    "                              \"robust_training\": {}, \"type_robust\": {}, \"epsilon_pgd_training\":{}}\n",
    "\n",
    "                to_exclude = [0]\n",
    "                experiment_list_tmp = [element for i, element in enumerate(experiment_list) if i not in to_exclude]\n",
    "                for exp in experiment_list_tmp:\n",
    "                    if not exp['data_set'] == dataset_id: \n",
    "                        continue\n",
    "                    for kk in parameters.keys():\n",
    "                        if exp[kk] in parameters[kk]:\n",
    "                            parameters[kk][exp[kk]].append(int(exp[\"model_name\"]))\n",
    "                        else:\n",
    "                            parameters[kk][exp[kk]] = [int(exp[\"model_name\"])]\n",
    "\n",
    "\n",
    "                # For all methods, do cross-val and create an entry of the results\n",
    "                backbones = [net, net+\"+pgd\"]\n",
    "\n",
    "\n",
    "\n",
    "                for backbone in backbones:\n",
    "                    for robust_training in [True, False]:\n",
    "                        if robust_training:\n",
    "                            type_robust_trainings = ['linf','l1',\"certificate\",'grad']\n",
    "                        else:\n",
    "                            type_robust_trainings = ['none']\n",
    "                        for type_robust in type_robust_trainings:\n",
    "\n",
    "                            if (backbone == 'Madry' and robust_training == True) or \\\n",
    "                                (backbone == 'CNN+clipping' and robust_training == False):\n",
    "                                continue\n",
    "\n",
    "                            if robust_training==False:\n",
    "                                ids = list(set(parameters[\"backbone\"][backbone]) & \n",
    "                                           set(parameters[\"robust_training\"][False]))\n",
    "                            else:\n",
    "                                ids = list(set(parameters[\"backbone\"][backbone]) & \n",
    "                                       set(parameters[\"robust_training\"][True])&\n",
    "                                      set(parameters[\"type_robust\"][type_robust]))\n",
    "\n",
    "\n",
    "\n",
    "                            if backbone == net + '+pgd' and robust_training == True:\n",
    "                                continue\n",
    "\n",
    "                            if ids == []:\n",
    "                                continue\n",
    "                            #print(ids)\n",
    "\n",
    "\n",
    "                            # Cross-validation among learning rates and epsilons:\n",
    "                            best_acc = -1\n",
    "                            best_id = ids[0]\n",
    "                            for id in ids:\n",
    "                                if ((robust_training == False) & (backbone==net) \\\n",
    "                                    & (experiment_list[id]['training_batch_size']==256)):\n",
    "                                    continue\n",
    "                                    \n",
    "                                file_name = results_dir + experiment_list[id]['model_name'] + '/results/acc_' + 'val' + '_' + attack + '.pkl'\n",
    "                                if not os.path.isfile(file_name):\n",
    "                                    print(\"Missing!! \" + file_name)\n",
    "                                    continue\n",
    "\n",
    "                                with open(file_name, 'rb') as f:\n",
    "                                    tmp_acc = pickle.load(f)\n",
    "\n",
    "                                acc = list(tmp_acc.values())[idx_epsilon] #tmp_acc[cv_epsilon]\n",
    "                                if acc>best_acc:\n",
    "                                    best_id = id\n",
    "                                    best_acc = acc\n",
    "\n",
    "                            if best_acc == -1:\n",
    "                                continue\n",
    "\n",
    "                            if (robust_training == False) & (backbone==net):  \n",
    "                                name_legend = 'vanilla'\n",
    "                            elif backbone== net + '+pgd':\n",
    "                                name_legend = 'pgd'\n",
    "                            else:\n",
    "                                if type_robust=='certificate':\n",
    "                                    name_legend = 'RUB'\n",
    "                                elif type_robust=='linf':\n",
    "                                    name_legend = 'aRUB_Linf'\n",
    "                                elif type_robust=='grad':\n",
    "                                    name_legend = 'grad'\n",
    "                                else:\n",
    "                                    name_legend = 'aRUB_L1'\n",
    "\n",
    "                            entry = {\"learning_rate\": experiment_list[best_id]['initial_learning_rate'],\n",
    "                                     \"net\": net,\n",
    "                                     \"dataset\": dataset_name,\n",
    "                                     \"standarize\": experiment_list[best_id]['standarize'],\n",
    "                                    \"robust_training\": name_legend,\n",
    "                                    \"epsilon\": experiment_list[best_id]['epsilon'],\n",
    "                                    \"epsilon_pgd_training\": experiment_list[best_id]['epsilon_pgd_training']}\n",
    "\n",
    "                            dataset = \"test\"\n",
    "                            entry[\"attack\"] = attack\n",
    "                            entry[\"experiment_id\"] = best_id\n",
    "\n",
    "                            with open(results_dir + experiment_list[best_id]['model_name'] + '/results/acc_' + dataset + '_' + \n",
    "                                attack + '.pkl', 'rb') as f:\n",
    "                                tmp_acc = pickle.load(f)\n",
    "\n",
    "                            entry[\"accuracy\"] =  100*(list(tmp_acc.values())[idx_epsilon]) #tmp_acc[cv_epsilon]\n",
    "                            entry[\"test_epsilon\"] = cv_epsilon\n",
    "\n",
    "                            list_entries.append(entry.copy())\n",
    "\n",
    "df_results = pd.DataFrame.from_dict(list_entries) \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}